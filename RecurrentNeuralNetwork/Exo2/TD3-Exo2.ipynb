{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f056f1e",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8903cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19202450",
   "metadata": {},
   "source": [
    "### 1 - Télécharger le fichier alice.txt depuis l’espace de cours. Charger ce fichier en python et afficher son contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3925e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_text = open(\"alice.txt\", encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed13d63",
   "metadata": {},
   "source": [
    "### 2 - Depuis la chaîne de caractères précédemment chargée, générer la liste de caractères uniques présents dans le livre. Écrire une méthode permettant de transformer chaque caratère en entier et inversement (chaque entier en caractère). Ceci est nécessaire car les réseaux de neurones ne travaillent pas sur des caractères mais sur des nombres !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "95ca2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_car = set()\n",
    "\n",
    "for letter in alice_text:\n",
    "    unique_car.add(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15f0fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_to_int = {}\n",
    "int_to_car = {}\n",
    "\n",
    "for i, c in enumerate(unique_car):\n",
    "    car_to_int[c] = i\n",
    "    int_to_car[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fc3b6",
   "metadata": {},
   "source": [
    "### 3 - Préparer un dataset contenant des séquences de 50 caractères (paramétrable) de longueur en entrée et le caractère suivant cette séquence en target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07024469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data, decalage):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - decalage):\n",
    "        X.append(data[i:i+decalage])\n",
    "        y.append(car_to_int[data[i+decalage]])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6108a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_y = create_dataframe(alice_text, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc4115d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x':data_X.tolist(), 'y':data_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1f5cd1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿The Project Gutenberg eBook of Alice’s Advent...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Project Gutenberg eBook of Alice’s Adventu...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he Project Gutenberg eBook of Alice’s Adventur...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e Project Gutenberg eBook of Alice’s Adventure...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Gutenberg eBook of Alice’s Adventures...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163961</th>\n",
       "      <td>ibe to our email newsletter to hear about new ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163962</th>\n",
       "      <td>be to our email newsletter to hear about new e...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163963</th>\n",
       "      <td>e to our email newsletter to hear about new eB...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163964</th>\n",
       "      <td>to our email newsletter to hear about new eBo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163965</th>\n",
       "      <td>to our email newsletter to hear about new eBoo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163966 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        x   y\n",
       "0       ﻿The Project Gutenberg eBook of Alice’s Advent...  84\n",
       "1       The Project Gutenberg eBook of Alice’s Adventu...  40\n",
       "2       he Project Gutenberg eBook of Alice’s Adventur...  47\n",
       "3       e Project Gutenberg eBook of Alice’s Adventure...  84\n",
       "4        Project Gutenberg eBook of Alice’s Adventures...  85\n",
       "...                                                   ...  ..\n",
       "163961  ibe to our email newsletter to hear about new ...  23\n",
       "163962  be to our email newsletter to hear about new e...  64\n",
       "163963  e to our email newsletter to hear about new eB...   6\n",
       "163964   to our email newsletter to hear about new eBo...  27\n",
       "163965  to our email newsletter to hear about new eBoo...  27\n",
       "\n",
       "[163966 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60524f0",
   "metadata": {},
   "source": [
    "### 4 - Transformer le dataset en séquence « one hot encodées »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae32dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[0;32m      3\u001b[0m enc \u001b[38;5;241m=\u001b[39m OneHotEncoder()\n\u001b[1;32m----> 4\u001b[0m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_encoders.py:991\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    974\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m    Fit OneHotEncoder to X.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;124;03m        Fitted encoder.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_drop_idx()\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_encoders.py:83\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[1;34m(self, X, handle_unknown, ensure_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[0;32m     81\u001b[0m _check_n_features(\u001b[38;5;28mself\u001b[39m, X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m _check_feature_names(\u001b[38;5;28mself\u001b[39m, X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 83\u001b[0m X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m n_features\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_encoders.py:49\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[1;34m(self, X, ensure_all_finite)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mPerform custom check_array:\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m- convert list of strings to object dtype\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     X_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(X_temp\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mstr_):\n\u001b[0;32m     51\u001b[0m         X \u001b[38;5;241m=\u001b[39m check_array(X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m, ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1092\u001b[0m             )\n\u001b[1;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_int = np.array([[car_to_int[ch] for ch in seq] for seq in df['x']], dtype=np.int32)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62f723d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163966, 50)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee69d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'] = X_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20da8182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          9\n",
       "1          8\n",
       "2         46\n",
       "3         36\n",
       "4         84\n",
       "          ..\n",
       "163961    40\n",
       "163962     1\n",
       "163963    36\n",
       "163964    84\n",
       "163965    65\n",
       "Name: x, Length: 163966, dtype: int32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
